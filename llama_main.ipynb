{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd  # type: ignore\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, get_scheduler, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import PeftModel, LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:24<00:00,  6.09s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.08480376642881861\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a 'customized integrated framework' in...</td>\n",
       "      <td>In the context of Audit and Assurance policy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the elements that audit and a...</td>\n",
       "      <td>Audit and assurance policies and procedures sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is it important to review and update the a...</td>\n",
       "      <td>It's important to review and update the audit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the role of an audit report in the aud...</td>\n",
       "      <td>An audit report plays a crucial role in the au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the purpose of follow-up activities in...</td>\n",
       "      <td>Follow-up activities are designed to monitor t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  What is a 'customized integrated framework' in...   \n",
       "1  What are some of the elements that audit and a...   \n",
       "2  Why is it important to review and update the a...   \n",
       "3  What is the role of an audit report in the aud...   \n",
       "4  What is the purpose of follow-up activities in...   \n",
       "\n",
       "                                              output  \n",
       "0  In the context of Audit and Assurance policy a...  \n",
       "1  Audit and assurance policies and procedures sh...  \n",
       "2  It's important to review and update the audit ...  \n",
       "3  An audit report plays a crucial role in the au...  \n",
       "4  Follow-up activities are designed to monitor t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_xml(\"./data/dataset.xml\")\n",
    "del df['index']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1038/1038 [00:00<00:00, 15592.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def instruct_format(examples):\n",
    "    inputs = examples['input']\n",
    "    targets = examples['output']\n",
    "    model_inputs = tokenizer(inputs, padding='max_length', max_length=128, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, padding='max_length', max_length=128, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "    \n",
    "\n",
    "def reg_format(row):\n",
    "    instruction = row[\"input\"]\n",
    "    response = row[\"output\"]\n",
    "    return tokenizer.prepare_seq2seq_batch(\n",
    "        src_texts=instruction,\n",
    "        tgt_texts=response,\n",
    "        return_tensors='pt',\n",
    "        max_length=512,  # Adjust the max length as needed\n",
    "        truncation=True  # Enable truncation\n",
    "    )\n",
    "    \n",
    "\n",
    "dataset = dataset.map(\n",
    "    instruct_format,\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\", \"output\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 934\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 104\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  <|begin_of_text|>Why is it important to test and review business continuity plans at planned intervals?[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "Output: <|begin_of_text|>Regular testing and reviewing are essential to ensure that the business continuity plans are up-to-date and effective. Changes in the business environment, operational structure, or technology may make current plans ineffective or inadequate. Regular reviews ensure that the plan is aligned with current circumstances and ready to be effectively implemented when needed.[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "decoded_input = tokenizer.decode(dataset['train']['input_ids'][0], skip_special_tokens=False)\n",
    "decoded_output = tokenizer.decode(dataset['train']['labels'][0], skip_special_tokens=False)\n",
    "print(f\"Input:  {decoded_input}\")\n",
    "print(f\"Output: {decoded_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=\"ccm_lora_weights\",\n",
    "    dataset_text_field=\"text\",\n",
    "    num_train_epochs=1,\n",
    "    max_seq_length=200,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer_config = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:51<?, ?it/s]\n",
      "                                                 \n",
      "100%|██████████| 117/117 [14:19<00:00,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9342875480651855, 'eval_runtime': 47.0979, 'eval_samples_per_second': 2.208, 'eval_steps_per_second': 0.276, 'epoch': 1.0}\n",
      "{'train_runtime': 859.5123, 'train_samples_per_second': 1.087, 'train_steps_per_second': 0.136, 'train_loss': 4.0795979296040334, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=117, training_loss=4.0795979296040334, metrics={'train_runtime': 859.5123, 'train_samples_per_second': 1.087, 'train_steps_per_second': 0.136, 'train_loss': 4.0795979296040334, 'epoch': 1.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    peft_config=lora_config,\n",
    "    args=sft_config,\n",
    ")\n",
    "\"\"\"\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=trainer_config,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.modeling_llama.LlamaForCausalLM"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"ccm_lora_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"ccm_lora_weights\", device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a 'customized integrated framework' in the context of an Audit and Assurance policy and procedure?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = \"\"\n",
    "for message in messages:\n",
    "    if message['role'] == 'system':\n",
    "        conversation_history += f\"System: {message['content']}\\n\"\n",
    "    elif message['role'] == 'user':\n",
    "        conversation_history += f\"User: {message['content']}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(ch):\n",
    "    inputs = tokenizer(ch, return_tensors='pt').to(device)\n",
    "    outputs = model.generate(**inputs, max_length=1024, pad_token_id=tokenizer.pad_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('System: \\n'\n",
      " \"User: What is a 'customized integrated framework' in the context of an Audit \"\n",
      " 'and Assurance policy and procedure?\\n'\n",
      " 'System: A customized integrated framework is a tailored approach to audit '\n",
      " 'and assurance that combines various elements, such as risk assessment, audit '\n",
      " 'procedures, and reporting, to meet the specific needs of an organization. It '\n",
      " 'is a customized framework that integrates different components to ensure '\n",
      " \"that audits are effective, efficient, and relevant to the organization's \"\n",
      " 'goals and objectives.\\n'\n",
      " '\\n'\n",
      " 'In the context of an Audit and Assurance policy and procedure, a customized '\n",
      " \"integrated framework would consider the organization's:\\n\"\n",
      " '\\n'\n",
      " \"1. Risk profile: The framework would take into account the organization's \"\n",
      " 'risk profile, including its business model, operations, and industry.\\n'\n",
      " \"2. Audit objectives: The framework would align with the organization's audit \"\n",
      " 'objectives, such as ensuring compliance with laws and regulations, improving '\n",
      " 'internal controls, and enhancing transparency.\\n'\n",
      " \"3. Stakeholders: The framework would consider the organization's \"\n",
      " 'stakeholders, including shareholders, customers, employees, and regulators.\\n'\n",
      " '4. Audit procedures: The framework would specify the audit procedures to be '\n",
      " 'used, including the types of audits, frequency, and scope.\\n'\n",
      " '5. Reporting: The framework would outline the reporting requirements, '\n",
      " 'including the format, frequency, and content of audit reports.\\n'\n",
      " '\\n'\n",
      " 'A customized integrated framework provides')\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "response = generate_response(conversation_history)\n",
    "pp.pprint(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
